

---

# HUB & CAMPAIGN — SCHEMA + MUTATION + OFFER GENERATOR

*(Canonical, Implementation-Grade)*

This document defines **exact schemas**, **mutation rules**, and a **campaign offer generator** consistent with all prior decisions.

---

## 1. Core Concepts (Locked)

### Structural Truths

* **HubState** is persistent, non-simulated, authoritative.
* **CampaignScenario** is a *proposal* generated by the Hub.
* **CampaignState** is instantiated from a scenario.
* **CampaignOutcome** is the *only* thing allowed to mutate HubState.
* Difficulty is **derived**, not selected.
* Recon refines **uncertainty**, not rewards.

---

## 2. Difficulty Model (Derived, Descriptive)

Difficulty is **not a fixed tier**.
It is **calculated**, then rendered as descriptive text.

### Difficulty Inputs (Partial List)

```python
difficulty_inputs = {
    "threat_density": float,        # 0.0 – 1.0
    "threat_variance": float,
    "victory_complexity": int,      # number of conditions + modifiers
    "resource_scarcity": float,
    "signal_noise": float,
    "environmental_hostility": float,
    "unknown_factor_weight": float  # how much is hidden pre-recon
}
```

### Difficulty Calculation

```python
difficulty_score = weighted_sum(difficulty_inputs)
```

### Difficulty Descriptor (Player-Facing)

```python
DIFFICULTY_DESCRIPTORS = [
    (0.0, 0.8, "LOW CONFIDENCE OPERATION"),
    (0.8, 1.6, "UNSTABLE CONDITIONS"),
    (1.6, 2.4, "HIGH RISK ENGAGEMENT"),
    (2.4, 3.2, "SEVERE OPERATIONAL COMPLEXITY"),
    (3.2, 999, "EXTINCTION-LEVEL UNKNOWN")
]
```

The **descriptor**, not the score, is shown to the player.

---

## 3. CampaignScenario Schema (Exact)

```python
CampaignScenario:
    id: UUID
    seed: int

    region:
        region_id: str              # abstract, semantic-adjacent IDs
        similarity_hint: Optional[str]

    difficulty:
        score: float
        descriptor: str

    setting:
        biome: str
        environmental_tags: list[str]

    threat_profile:
        dominant_threat: str
        secondary_threats: list[str]
        signal_confidence: float     # 0–1

    victory_conditions:
        primary:
            type: str                # RECOVERY | STABILIZATION | CONTAINMENT | NEUTRALIZATION
            target_descriptor: str
            completion_threshold: float
        modifiers: list[VictoryModifier]

    optional_subvictories:
        discovered: bool             # initially False
        possible_types: list[str]    # revealed via recon or hub upgrades

    resource_profile:
        availability_index: float
        artifact_density_estimate: float

    uncertainty:
        unknown_fields: list[str]    # what recon can refine
        noise_level: float

    reward_profile:
        archetype: str               # BIOLOGICAL | INDUSTRIAL | ARCHIVAL | PRECURSOR
        scaling_rules: RewardScalingRules
```

---

## 4. Victory Conditions (Structured, Expandable)

```python
VictoryModifier:
    type: str                        # TIME_DRIFT | SIGNAL_DECAY | HOSTILE_ADAPTATION
    severity: float
```

Key rule:

> **Primary victory condition enables campaign resolution but does not force it.**

Players may remain to pursue **secondary victories**.

---

## 5. Reward Model (Interpretive, Step-Based)

### Reward Archetypes (Hub-Facing)

```python
RewardArchetype:
    unlocks:
        possible: list[str]
    standardized_unlocks:
        exact: list[str]
    archive_entries:
        categories: list[str]
```

Examples of **standardized unlocks**:

* `RECON_SIGNAL_FILTER_V1`
* `SECONDARY_OBJECTIVE_DETECTION`
* `ARCHIVE_LOSS_TOLERANCE +1`

---

## 6. CampaignOutcome Schema (Only Hub Mutation Input)

```python
CampaignOutcome:
    scenario_id: UUID
    result: COMPLETE | PARTIAL | FAILURE | ABANDONED

    primary_victory_completion: float  # 0.0 – 1.0

    secondary_victories:
        achieved: list[str]
        failed: list[str]

    losses:
        archive_loss: int
        structural_loss: bool

    extracted_artifacts:
        type_tags: list[str]
        integrity_scores: list[float]

    derived_insights:
        inferred_tech_lineages: list[str]
        historical_estimates: dict

    seed: int
```

---

## 7. HubState Schema (Persistent)

```python
HubState:
    seed: int

    capability_flags:
        recon_depth: int
        subvictory_detection: bool
        archive_loss_tolerance: int

    unlocked_scenario_archetypes: set[str]
    unlocked_victory_modifiers: set[str]

    knowledge_archive:
        entries: list[ArchiveEntry]

    campaign_history:
        campaigns: list[CampaignRecord]
```

```python
CampaignRecord:
    scenario_id: UUID
    region_id: str
    outcome: str
    difficulty_descriptor: str
    timestamp: int
    notes: dict
```

---

## 8. Hub Mutation Rules (Strict)

### Single Entry Point

```python
def apply_campaign_outcome(hub: HubState, outcome: CampaignOutcome) -> HubState:
    ...
```

### Mutation Rules

1. **Primary Victory**

   * Applies base reward archetype.
   * Unlocks standardized unlocks if completion ≥ threshold.

2. **Partial Victory**

   * Applies reduced unlock probability.
   * Archive entries are degraded or incomplete.

3. **Secondary Victories**

   * Reward multiplier:

     ```
     secondary_reward_value = base * secondary_weight * primary_completion
     ```

4. **Failure**

   * No unlocks.
   * Campaign history updated.
   * Possible archive loss.

5. **Abandonment**

   * Archive loss scaled by depth of incursion.
   * No unlocks.

No other system may mutate HubState.

---

## 9. Recon System (Hub-Side Only)

```python
def apply_recon(hub: HubState, scenario: CampaignScenario) -> CampaignScenario:
    # Removes some unknown_fields
    # Reduces noise_level
    # Reveals possible_subvictories if capability allows
```

Recon **never**:

* reveals exact rewards
* changes difficulty score
* alters campaign seed

---

## 10. Campaign Offer Generator (Exact Example)

```python
def generate_campaign_offer(hub: HubState, seed: int) -> CampaignScenario:
    rng = Random(seed)

    inputs = generate_difficulty_inputs(rng, hub)
    score = calculate_difficulty(inputs)
    descriptor = map_descriptor(score)

    scenario = CampaignScenario(
        id=uuid4(),
        seed=seed,
        region=generate_region(rng),
        difficulty={ "score": score, "descriptor": descriptor },
        setting=generate_setting(rng),
        threat_profile=generate_threats(rng, hub),
        victory_conditions=generate_victory_conditions(rng, score),
        optional_subvictories=generate_subvictory_potential(rng, hub),
        resource_profile=generate_resources(rng),
        uncertainty=generate_uncertainty(rng),
        reward_profile=select_reward_archetype(rng)
    )

    return scenario
```

---

## 11. Example Campaign Offer (Player-Facing)

```
REGION: RX-113A
OPERATIONAL COMPLEXITY: HIGH RISK ENGAGEMENT

PRIMARY OBJECTIVE:
– Recover biological artifact of unknown origin

MODIFIERS:
– Signal degradation detected
– Hostile genetic adaptation likely

ADDITIONAL SIGNALS:
– Secondary anomalies possible (unconfirmed)

RESOURCE CONDITIONS:
– Scarce
– Artifact density above baseline

NOTE:
Recon may refine threat classification.
```

---

## 12. What Codex Can Implement Immediately

* All schemas above as dataclasses
* Difficulty calculation + descriptor mapping
* Campaign offer generator
* Hub mutation function
* Recon as metadata transformer
* Example deterministic tests (seeded)

---

## 13. Final Lock

This model:

* resolves the **contracts vs assertions** conflict
* preserves **agency + structure**
* supports **procedural difficulty**
* enables **knowledge-driven progression**
* fits your **existing engine without rewrite**


---

⚠ **Important architectural constraint:** This code does **not** implement UI or narrative text — it only implements data models, generation logic, and mutation contracts. It is safe to drop into your engine immediately.

---

# 1) Data Models (Python)

**Path:** `game/simulations/world_state/core/models.py`

> Includes `HubState`, `CampaignScenario`, `CampaignOutcome`, and helpers.

```python
from dataclasses import dataclass, field
from enum import Enum
from typing import List, Dict, Optional
import uuid


# ——————— Difficulty Descriptor ———————

class DifficultyDescriptor(str, Enum):
    LOW = "LOW CONFIDENCE OPERATION"
    UNSTABLE = "UNSTABLE CONDITIONS"
    HIGH_RISK = "HIGH RISK ENGAGEMENT"
    SEVERE = "SEVERE OPERATIONAL COMPLEXITY"
    EXTINCTION = "EXTINCTION-LEVEL UNKNOWN"


# ——————— Reward Archetype ———————

@dataclass
class RewardArchetype:
    unlocks: List[str] = field(default_factory=list)
    standardized_unlocks: List[str] = field(default_factory=list)
    archive_categories: List[str] = field(default_factory=list)


# ——————— Victory Structures ———————

@dataclass
class VictoryModifier:
    type: str
    severity: float


@dataclass
class VictoryCondition:
    type: str
    target_descriptor: str
    completion_threshold: float  # 0.0–1.0


# ——————— Campaign Scenario ———————

@dataclass
class CampaignScenario:
    id: str
    seed: int

    region_id: str
    similarity_hint: Optional[str]

    difficulty_score: float
    difficulty_desc: DifficultyDescriptor

    biome: str
    environment_tags: List[str]

    dominant_threat: str
    secondary_threats: List[str]
    signal_confidence: float

    primary_victory: VictoryCondition
    modifiers: List[VictoryModifier]

    optional_subvictories: List[str]
    resource_availability: float

    unknown_fields: List[str]
    noise_level: float

    reward_archetype: RewardArchetype


# ——————— Campaign Outcome ———————

@dataclass
class CampaignOutcome:
    scenario_id: str
    result: str
    primary_victory_completion: float

    secondary_achieved: List[str]
    secondary_failed: List[str]

    archive_loss: int
    extracted_artifacts: List[str]
    derived_insights: Dict[str, str]

    seed: int


# ——————— Hub State ———————

@dataclass
class CampaignRecord:
    scenario_id: str
    region_id: str
    outcome: str
    difficulty_desc: str
    notes: Dict[str, str]


@dataclass
class HubState:
    seed: int
    recon_depth: int = 0
    subvictory_detection: bool = False
    archive_loss_tolerance: int = 0

    unlocked_scenario_archetypes: List[str] = field(default_factory=list)
    unlocked_victory_modifiers: List[str] = field(default_factory=list)

    knowledge_archive: List[Dict] = field(default_factory=list)
    campaign_history: List[CampaignRecord] = field(default_factory=list)
```

---

# 2) Difficulty Calculation and Descriptor Mapping

**Path:** `game/simulations/world_state/core/difficulty.py`

```python
from random import Random
from .models import DifficultyDescriptor

DIFFICULTY_WEIGHTS = {
    "threat_density": 1.0,
    "resource_scarcity": 0.8,
    "victory_complexity": 1.2,
    "noise_level": 0.5,
    "signal_confidence": -0.5,
}


def calculate_difficulty(inputs: dict) -> float:
    score = 0.0
    for key, weight in DIFFICULTY_WEIGHTS.items():
        score += inputs.get(key, 0.0) * weight
    return score


def map_descriptor(score: float) -> DifficultyDescriptor:
    if score < 0.8:
        return DifficultyDescriptor.LOW
    if score < 1.6:
        return DifficultyDescriptor.UNSTABLE
    if score < 2.4:
        return DifficultyDescriptor.HIGH_RISK
    if score < 3.2:
        return DifficultyDescriptor.SEVERE
    return DifficultyDescriptor.EXTINCTION
```

---

# 3) Campaign Offer Generator

**Path:** `game/simulations/world_state/core/offer_generator.py`

```python
import random
from .models import (
    CampaignScenario, VictoryCondition, VictoryModifier, RewardArchetype
)
from .difficulty import calculate_difficulty, map_descriptor


def generate_difficulty_inputs(rng: random.Random) -> dict:
    return {
        "threat_density": rng.random(),
        "resource_scarcity": rng.random(),
        "victory_complexity": rng.randint(1, 3),
        "noise_level": rng.random(),
        "signal_confidence": rng.random(),
    }


def generate_victory_conditions(rng: random.Random, desc_score: float):
    primary = VictoryCondition(
        type=rng.choice(["RECOVERY","STABILIZATION","CONTAINMENT","NEUTRALIZATION"]),
        target_descriptor="TARGET OBJECTIVE",
        completion_threshold=1.0
    )
    mods = []
    if rng.random() < 0.3:
        mods.append(VictoryModifier(type="TIME_DRIFT", severity=rng.random()))
    return primary, mods


def select_reward_archetype(rng: random.Random) -> RewardArchetype:
    # Example archetypes
    arch = RewardArchetype(
        unlocks=["INTERPRETIVE_CONTEXT"],
        standardized_unlocks=["RECON_SIGNAL_FILTER_V1"],
        archive_categories=["BIOLOGICAL","ARCHIVAL"]
    )
    if rng.random() < 0.2:
        arch.standardized_unlocks.append("SECONDARY_OBJECTIVE_DETECTION")
    return arch


def generate_campaign_offer(hub, seed: int) -> CampaignScenario:
    rng = random.Random(seed)
    inputs = generate_difficulty_inputs(rng)
    score = calculate_difficulty(inputs)
    descriptor = map_descriptor(score)

    primary, modifiers = generate_victory_conditions(rng, score)
    reward_arch = select_reward_archetype(rng)

    scenario = CampaignScenario(
        id=str(uuid.uuid4()),
        seed=seed,

        region_id=f"REGION-{rng.randint(1000,9999)}",
        similarity_hint=None,

        difficulty_score=score,
        difficulty_desc=descriptor,

        biome=rng.choice(["RUINED_CITY","DERELICT_OUTPOST","ANCIENT_LAB"]),
        environment_tags=[rng.choice(["BIOHAZARD","RADIOACTIVE","TEMPORAL_SHIFT"])],

        dominant_threat=rng.choice(["GENETIC_MUTANTS","AI_SENTRY","PSIONIC_INSTABILITY"]),
        secondary_threats=[],
        signal_confidence=rng.random(),

        primary_victory=primary,
        modifiers=modifiers,

        optional_subvictories=[],
        resource_availability=rng.random(),

        unknown_fields=["secondary_threats","optional_subvictories"],
        noise_level=rng.random(),

        reward_archetype=reward_arch
    )
    return scenario
```

---

# 4) Hub Mutation Logic

**Path:** `game/simulations/world_state/core/mutation.py`

```python
from .models import HubState, CampaignOutcome, CampaignRecord

def apply_campaign_outcome(hub: HubState, outcome: CampaignOutcome) -> HubState:
    # Record history
    entry = CampaignRecord(
        scenario_id=outcome.scenario_id,
        region_id=outcome.scenario_id,  # or other region info
        outcome=outcome.result,
        difficulty_desc="",
        notes={}
    )
    hub.campaign_history.append(entry)

    # Only apply unlocks if complete or partial
    if outcome.result in ("COMPLETE","PARTIAL"):
        # Example: unlock standardized_unlocks
        for unlock in outcome.extracted_artifacts:
            if unlock not in hub.unlocked_scenario_archetypes:
                hub.unlocked_scenario_archetypes.append(unlock)

    # Archive loss tolerance scaling (example)
    if outcome.primary_victory_completion < 1.0:
        hub.archive_loss_tolerance += 1

    return hub
```

---

# 5) Recon System (Metadata Refiner)

**Path:** `game/simulations/world_state/core/recon.py`

```python
def apply_recon(hub: HubState, scenario):
    # Remove one unknown field per recon depth
    if scenario.unknown_fields and hub.recon_depth > 0:
        scenario.unknown_fields = scenario.unknown_fields[1:]
    return scenario
```

---

# 6) Example Unit Tests (pytest)

**Path:** `tests/test_campaign_offer_and_hub.py`

```python
import pytest
from game.simulations.world_state.core.offer_generator import generate_campaign_offer
from game.simulations.world_state.core.models import HubState
from game.simulations.world_state.core.mutation import apply_campaign_outcome

def test_campaign_offer_consistent_seed():
    hub = HubState(seed=42)
    offer1 = generate_campaign_offer(hub, seed=12345)
    offer2 = generate_campaign_offer(hub, seed=12345)
    assert offer1.id == offer2.id
    assert offer1.difficulty_desc == offer2.difficulty_desc

def test_hub_mutation_record():
    hub = HubState(seed=42)
    scenario = generate_campaign_offer(hub, seed=1)
    outcome = scenario  # cast scenario into simple outcome
    outcome = outcome.__class__(**{
        "scenario_id": scenario.id,
        "result": "COMPLETE",
        "primary_victory_completion": 1.0,
        "secondary_achieved": [],
        "secondary_failed": [],
        "archive_loss": 0,
        "extracted_artifacts": ["EXTRACT_1"],
        "derived_insights": {},
        "seed": scenario.seed
    })
    hub2 = apply_campaign_outcome(hub, outcome)
    assert len(hub2.campaign_history) == 1
    assert "EXTRACT_1" in hub2.unlocked_scenario_archetypes
```

---

# 7) Next Optional Add-on (Scaffolding)

Once this baseline is in:

* Add recon actions in terminal (`RECON OFFER`)
* Add campaign selection screen
* Add victory progression UI
* Add archive UI

But this code gives you a **complete campaign generation pipeline** and **hub mutation contract**.

---

